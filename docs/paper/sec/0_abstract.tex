\begin{abstract}
Gaze prediction for images could see applications in user interfaces, data
visualizations, and digital media to give developers and producers feedback on
where viewers fixate. Visual fixations might be used as a proxy for viewer's
attention-to-detail. State-of-the-art models for gaze prediction use deep
learning techniques, and problematically, most published training data is biased
towards "candid photography": minimally altered photographs for practical use.
Our applications of interest deal with stylized or abstract images,
characterized by the use of computational generative and transformative
techniques, in contrast to candid photography. Our study shows that
state-of-the-art models perform significantly worse on common image
transformations, including cropping, rotation, contrast adjustment, and noise.
We fail to find any post-hoc indicators of confidence or degradation in
prediction accuracy for arbitrary transformations; comparison against human
trials is the only reliable indicator of performance. Our work emphasizes the
need for more varied training data in order to confidently apply gaze prediction
models in digital media contexts.
\end{abstract}